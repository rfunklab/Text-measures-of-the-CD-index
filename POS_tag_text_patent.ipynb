{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-Setup\" data-toc-modified-id=\"Python-Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Python Setup</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Patents-with-index-below-0\" data-toc-modified-id=\"Patents-with-index-below-0-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Patents with index below 0</a></span></li><li><span><a href=\"#Patents-with-index-above-0\" data-toc-modified-id=\"Patents-with-index-above-0-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Patents with index above 0</a></span></li><li><span><a href=\"#Find-which-verbs-and-nouns-are-unique-to-above_0-and-below_0-patents\" data-toc-modified-id=\"Find-which-verbs-and-nouns-are-unique-to-above_0-and-below_0-patents-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Find which verbs and nouns are unique to above_0 and below_0 patents</a></span></li><li><span><a href=\"#Patents-with-index-1\" data-toc-modified-id=\"Patents-with-index-1-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Patents with index 1</a></span></li><li><span><a href=\"#Patents-with-closer-to--1-index\" data-toc-modified-id=\"Patents-with-closer-to--1-index-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Patents with closer to -1 index</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# POS tagging\n",
    "\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')  # this is the large model to train on: https://spacy.io/models/en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8: expected 15 fields, saw 18\\nSkipping line 38: expected 15 fields, saw 19\\nSkipping line 65: expected 15 fields, saw 23\\nSkipping line 99: expected 15 fields, saw 21\\nSkipping line 101: expected 15 fields, saw 21\\nSkipping line 121: expected 15 fields, saw 25\\nSkipping line 122: expected 15 fields, saw 25\\nSkipping line 131: expected 15 fields, saw 21\\nSkipping line 138: expected 15 fields, saw 25\\nSkipping line 144: expected 15 fields, saw 20\\nSkipping line 148: expected 15 fields, saw 26\\nSkipping line 151: expected 15 fields, saw 43\\nSkipping line 153: expected 15 fields, saw 31\\nSkipping line 156: expected 15 fields, saw 27\\nSkipping line 160: expected 15 fields, saw 25\\nSkipping line 161: expected 15 fields, saw 25\\nSkipping line 172: expected 15 fields, saw 16\\nSkipping line 177: expected 15 fields, saw 21\\n'\n"
     ]
    }
   ],
   "source": [
    "text = pd.read_csv('patents_text_cdindex_i_2017y_gt_1000_20190901.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text[['patent_number','title','abstract','cd_2017y','mcd_2017y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patents with index below 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_below_0 = text[text['cd_2017y'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use POS tagging in spacy\n",
    "\n",
    "results_below_0 = []\n",
    "for index,i in enumerate(text_below_0['title']):\n",
    "    doc = nlp(i)\n",
    "    for token in doc:\n",
    "        results_below_0.append([index,token.lemma_, token.pos_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_below_0 = pd.DataFrame(results_below_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mesh</td>\n",
       "      <td>PROPN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tissue</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>fastener</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>disposable</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0           1      2\n",
       "0  0        mesh  PROPN\n",
       "1  0      tissue   NOUN\n",
       "2  0    fastener   NOUN\n",
       "3  1  disposable    ADJ\n",
       "4  1      linear    ADJ"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_below_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all verbs \n",
    "\n",
    "results_below_0_verbs = results_below_0[results_below_0[2] == 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique verbs\n",
    "\n",
    "count_below_0_verbs = Counter(results_below_0_verbs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of unique verbs\n",
    "\n",
    "set_below_0_verbs = list(set(results_below_0_verbs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all nouns\n",
    "\n",
    "results_below_0_nouns = results_below_0[results_below_0[2] == 'NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of unique nouns\n",
    "\n",
    "count_below_0_nouns = Counter(results_below_0_nouns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of unique nouns\n",
    "\n",
    "set_below_0_nouns = list(set(results_below_0_nouns[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patents with index above 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_above_0 = text[text['cd_2017y'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use POS tagging in spacy\n",
    "\n",
    "results_above_0 = []\n",
    "for index,i in enumerate(text_above_0['title']):\n",
    "    doc = nlp(i)\n",
    "    for token in doc:\n",
    "        results_above_0.append([index,token.lemma_, token.pos_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_above_0 = pd.DataFrame(results_above_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>process</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>produce</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>porous</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>product</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1     2\n",
       "0  0  process  NOUN\n",
       "1  0      for   ADP\n",
       "2  0  produce  VERB\n",
       "3  0   porous   ADJ\n",
       "4  0  product  NOUN"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_above_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all verbs\n",
    "\n",
    "results_above_0_verbs = results_above_0[results_above_0[2] == 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all nouns\n",
    "\n",
    "results_above_0_nouns = results_above_0[results_above_0[2] == 'NOUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique nouns\n",
    "\n",
    "set_above_0_nouns = list(set(results_above_0_nouns[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique nouns\n",
    "\n",
    "count_above_0_nouns = Counter(results_above_0_nouns[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique verbs\n",
    "\n",
    "set_above_0_verbs = list(set(results_above_0_verbs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique verbs\n",
    "\n",
    "count_above_0_verbs = Counter(results_above_0_verbs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find which verbs and nouns are unique to above_0 and below_0 patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_nouns_in_above_0 = list(set(set_above_0_nouns) - set(set_below_0_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_nouns_in_below_0 = list(set(set_below_0_nouns) - set(set_above_0_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_verbs_in_above_0 = list(set(set_above_0_verbs) - set(set_below_0_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_verbs_in_below_0 = list(set(set_below_0_verbs) - set(set_above_0_verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['perform',\n",
       " 'copyright',\n",
       " 'simulate',\n",
       " 'lh283btmon810',\n",
       " 'cool',\n",
       " 'ablate',\n",
       " 'analyze',\n",
       " 'bifurcate',\n",
       " 'expand',\n",
       " 'classify',\n",
       " 'sense',\n",
       " 'game',\n",
       " 'utilize',\n",
       " 'process',\n",
       " 'trap',\n",
       " 'end',\n",
       " 'integrate',\n",
       " 'monitor',\n",
       " 'select',\n",
       " 'obtain',\n",
       " 'transmit',\n",
       " 'stack',\n",
       " 'manage']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique verbs in below_0\n",
    "\n",
    "difference_verbs_in_below_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['incorporate',\n",
       " 'deliver',\n",
       " 'project',\n",
       " 'win',\n",
       " 'generate',\n",
       " 'authenticate',\n",
       " 'etch',\n",
       " 'transfer',\n",
       " 'interact',\n",
       " 'design',\n",
       " 'internetwork',\n",
       " 'assist',\n",
       " 'track',\n",
       " 'present',\n",
       " 'make',\n",
       " 'manufacture',\n",
       " 'read',\n",
       " 'create',\n",
       " 'form',\n",
       " 'customize',\n",
       " 'emulate',\n",
       " 'facilitate',\n",
       " 'target',\n",
       " 'delay',\n",
       " 'determine',\n",
       " 'write',\n",
       " 'attach',\n",
       " 'balance',\n",
       " 'nonwoven',\n",
       " 'apply',\n",
       " 'say',\n",
       " 'define',\n",
       " 'contact',\n",
       " 'measure',\n",
       " 'drive',\n",
       " 'comprise',\n",
       " 'bind',\n",
       " 'link',\n",
       " 'modify',\n",
       " 'include']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique verbs in above_0\n",
    "\n",
    "difference_verbs_in_above_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patents with index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = text[text['cd_2017y'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging with textblob\n",
    "\n",
    "results_1_textblob = []\n",
    "for index,i in enumerate(text_1['title']):\n",
    "    blob = TextBlob(i)\n",
    "    for words, tag in blob.tags:\n",
    "        results_1_textblob.append([index,words,tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 'Process', 'NN'],\n",
       " [0, 'for', 'IN'],\n",
       " [0, 'producing', 'VBG'],\n",
       " [0, 'porous', 'JJ'],\n",
       " [0, 'products', 'NNS'],\n",
       " [1, 'Nonwoven', 'NNP'],\n",
       " [1, 'fabric', 'NN'],\n",
       " [1, 'and', 'CC'],\n",
       " [1, 'method', 'NN'],\n",
       " [1, 'of', 'IN'],\n",
       " [1, 'producing', 'VBG'],\n",
       " [1, 'same', 'JJ'],\n",
       " [2, 'Cryptographic', 'NNP'],\n",
       " [2, 'communications', 'NNS'],\n",
       " [2, 'system', 'NN'],\n",
       " [2, 'and', 'CC'],\n",
       " [2, 'method', 'NN'],\n",
       " [3, 'Process', 'NN'],\n",
       " [3, 'for', 'IN'],\n",
       " [3, 'amplifying', 'VBG'],\n",
       " [3, 'nucleic', 'JJ'],\n",
       " [3, 'acid', 'NN'],\n",
       " [3, 'sequences', 'NNS'],\n",
       " [4, 'Inbred', 'NNP'],\n",
       " [4, 'corn', 'NN'],\n",
       " [4, 'line', 'NN'],\n",
       " [4, 'PHT47', 'NNP'],\n",
       " [5, 'Mutant', 'JJ'],\n",
       " [5, 'dwarfism', 'NN'],\n",
       " [5, 'gene', 'NN'],\n",
       " [5, 'of', 'IN'],\n",
       " [5, 'petunia', 'NN'],\n",
       " [6, 'Inbred', 'NNP'],\n",
       " [6, 'maize', 'MD'],\n",
       " [6, 'line', 'NN'],\n",
       " [6, 'PH0HC', 'VB'],\n",
       " [7, 'Oxide', 'NNP'],\n",
       " [7, 'thin', 'JJ'],\n",
       " [7, 'film', 'NN'],\n",
       " [8, 'Field-effect', 'JJ'],\n",
       " [8, 'transistor', 'NN'],\n",
       " [8, 'and', 'CC'],\n",
       " [8, 'method', 'NN'],\n",
       " [8, 'for', 'IN'],\n",
       " [8, 'manufacturing', 'VBG'],\n",
       " [8, 'the', 'DT'],\n",
       " [8, 'same', 'JJ']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_1_textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = []\n",
    "for index,i in enumerate(text_1['title']):\n",
    "    doc = nlp(i)\n",
    "    for token in doc:\n",
    "        results_1.append([index,token.lemma_, token.pos_,token.tag_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = pd.DataFrame(results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all verbs \n",
    "\n",
    "results_1_verbs = results_1[results_1[2] == 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'produce': 2, 'nonwoven': 1, 'amplify': 1, 'manufacture': 1})"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count unique verbs\n",
    "\n",
    "Counter(results_1_verbs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amplify', 'manufacture', 'nonwoven', 'produce'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique verbs\n",
    "\n",
    "set(results_1_verbs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1_nouns = results_1[results_1[2] == 'NOUN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patents with closer to -1 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_minus_1 = text[text['cd_2017y'] < -0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS tagging with spacy\n",
    "\n",
    "results_minus_1 = []\n",
    "for index,i in enumerate(text_minus_1['title']):\n",
    "    doc = nlp(i)\n",
    "    for token in doc:\n",
    "        results_minus_1.append([index,token.lemma_, token.pos_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_minus_1 = pd.DataFrame(results_minus_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all verbs\n",
    "\n",
    "results_minus_1_verbs = results_minus_1[results_minus_1[2] == 'VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'use': 1, 'fabricate': 1})"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count unique verbs\n",
    "\n",
    "Counter(results_minus_1_verbs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fabricate', 'use'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique verbs\n",
    "\n",
    "set(results_minus_1_verbs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique nouns\n",
    "\n",
    "results_minus_1_nouns = results_minus_1[results_minus_1[2] == 'NOUN']"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
